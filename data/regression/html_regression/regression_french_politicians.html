<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>impression_count</td> <th>  R-squared:         </th>  <td>   0.178</td>  
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.177</td>  
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   192.9</td>  
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 07 Jun 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   
</tr>
<tr>
  <th>Time:</th>                 <td>22:45:20</td>     <th>  Log-Likelihood:    </th> <td>-3.4546e+05</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td> 24928</td>      <th>  AIC:               </th>  <td>6.910e+05</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 24899</td>      <th>  BIC:               </th>  <td>6.912e+05</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>      <td> </td>     
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     
</tr>
</table>
<table class="simpletable">
<tr>
                <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                    <td>-1.526e+04</td> <td> 7820.308</td> <td>   -1.952</td> <td> 0.051</td> <td>-3.06e+04</td> <td>   65.726</td>
</tr>
<tr>
  <th>dummy_annehidalgo</th>            <td>-1.107e+05</td> <td> 9973.752</td> <td>  -11.102</td> <td> 0.000</td> <td> -1.3e+05</td> <td>-9.12e+04</td>
</tr>
<tr>
  <th>dummy_emmanuelmacron</th>         <td> 2.885e+04</td> <td> 5808.972</td> <td>    4.966</td> <td> 0.000</td> <td> 1.75e+04</td> <td> 4.02e+04</td>
</tr>
<tr>
  <th>dummy_florianphilippot</th>       <td> 6054.5773</td> <td> 1.02e+04</td> <td>    0.593</td> <td> 0.553</td> <td>-1.39e+04</td> <td> 2.61e+04</td>
</tr>
<tr>
  <th>dummy_francepoliticalfigures</th> <td> 3894.9089</td> <td> 6846.448</td> <td>    0.569</td> <td> 0.569</td> <td>-9524.535</td> <td> 1.73e+04</td>
</tr>
<tr>
  <th>dummy_francepolitics</th>         <td> 1.074e+04</td> <td> 7628.057</td> <td>    1.408</td> <td> 0.159</td> <td>-4208.523</td> <td> 2.57e+04</td>
</tr>
<tr>
  <th>dummy_frenchqag</th>              <td> 8772.7073</td> <td> 6138.536</td> <td>    1.429</td> <td> 0.153</td> <td>-3259.188</td> <td> 2.08e+04</td>
</tr>
<tr>
  <th>dummy_gralddarmanin</th>          <td> 1.984e+04</td> <td> 9702.780</td> <td>    2.045</td> <td> 0.041</td> <td>  820.494</td> <td> 3.89e+04</td>
</tr>
<tr>
  <th>dummy_jeanlucmlenchon</th>        <td>-1.609e+05</td> <td> 7954.723</td> <td>  -20.230</td> <td> 0.000</td> <td>-1.77e+05</td> <td>-1.45e+05</td>
</tr>
<tr>
  <th>dummy_jordanbardella</th>         <td> 2.372e+04</td> <td> 1.03e+04</td> <td>    2.297</td> <td> 0.022</td> <td> 3476.759</td> <td>  4.4e+04</td>
</tr>
<tr>
  <th>dummy_lisabethborne</th>          <td> 2.218e+04</td> <td> 9495.654</td> <td>    2.336</td> <td> 0.020</td> <td> 3567.485</td> <td> 4.08e+04</td>
</tr>
<tr>
  <th>dummy_marinelepen</th>            <td>-1.382e+05</td> <td> 9550.073</td> <td>  -14.475</td> <td> 0.000</td> <td>-1.57e+05</td> <td> -1.2e+05</td>
</tr>
<tr>
  <th>dummy_nathalieloiseau</th>        <td> 1.891e+04</td> <td> 9706.519</td> <td>    1.948</td> <td> 0.051</td> <td> -118.564</td> <td> 3.79e+04</td>
</tr>
<tr>
  <th>dummy_news</th>                   <td> -899.9031</td> <td> 6050.981</td> <td>   -0.149</td> <td> 0.882</td> <td>-1.28e+04</td> <td>  1.1e+04</td>
</tr>
<tr>
  <th>dummy_nicolasdupontaignan</th>    <td>-2.266e+04</td> <td> 9854.784</td> <td>   -2.299</td> <td> 0.021</td> <td> -4.2e+04</td> <td>-3343.998</td>
</tr>
<tr>
  <th>dummy_politicalfigures</th>       <td>-1.571e+04</td> <td> 8642.032</td> <td>   -1.818</td> <td> 0.069</td> <td>-3.26e+04</td> <td> 1228.940</td>
</tr>
<tr>
  <th>dummy_politicalissues</th>        <td>-9242.3668</td> <td> 9370.151</td> <td>   -0.986</td> <td> 0.324</td> <td>-2.76e+04</td> <td> 9123.684</td>
</tr>
<tr>
  <th>dummy_politics</th>               <td> 4819.4848</td> <td> 7864.793</td> <td>    0.613</td> <td> 0.540</td> <td>-1.06e+04</td> <td> 2.02e+04</td>
</tr>
<tr>
  <th>dummy_ricciotti</th>              <td> 5376.1806</td> <td> 9729.784</td> <td>    0.553</td> <td> 0.581</td> <td>-1.37e+04</td> <td> 2.44e+04</td>
</tr>
<tr>
  <th>dummy_riczemmour</th>             <td> 4.911e+04</td> <td> 1.01e+04</td> <td>    4.873</td> <td> 0.000</td> <td> 2.94e+04</td> <td> 6.89e+04</td>
</tr>
<tr>
  <th>dummy_sandrinerousseau</th>       <td> 5.367e+04</td> <td> 9597.501</td> <td>    5.592</td> <td> 0.000</td> <td> 3.49e+04</td> <td> 7.25e+04</td>
</tr>
<tr>
  <th>hashtags_count</th>               <td>-3602.3245</td> <td> 1863.176</td> <td>   -1.933</td> <td> 0.053</td> <td>-7254.259</td> <td>   49.610</td>
</tr>
<tr>
  <th>mentions_count</th>               <td>-8086.9318</td> <td> 1271.842</td> <td>   -6.358</td> <td> 0.000</td> <td>-1.06e+04</td> <td>-5594.046</td>
</tr>
<tr>
  <th>tweet_external_urls_count</th>    <td> 1.496e+04</td> <td> 3844.607</td> <td>    3.890</td> <td> 0.000</td> <td> 7421.633</td> <td> 2.25e+04</td>
</tr>
<tr>
  <th>tweet_length</th>                 <td>   73.0305</td> <td>   24.660</td> <td>    2.961</td> <td> 0.003</td> <td>   24.695</td> <td>  121.366</td>
</tr>
<tr>
  <th>tweet_medias_count</th>           <td> 3093.5201</td> <td> 2089.520</td> <td>    1.480</td> <td> 0.139</td> <td>-1002.064</td> <td> 7189.104</td>
</tr>
<tr>
  <th>tweet_period</th>                 <td>  244.3240</td> <td>  335.545</td> <td>    0.728</td> <td> 0.467</td> <td> -413.365</td> <td>  902.013</td>
</tr>
<tr>
  <th>tweet_sentiment</th>              <td>-3211.1813</td> <td> 6273.653</td> <td>   -0.512</td> <td> 0.609</td> <td>-1.55e+04</td> <td> 9085.550</td>
</tr>
<tr>
  <th>followers_count</th>              <td>    0.1219</td> <td>    0.002</td> <td>   67.868</td> <td> 0.000</td> <td>    0.118</td> <td>    0.125</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>60574.631</td> <th>  Durbin-Watson:     </th>   <td>   1.720</td>   
</tr>
<tr>
  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>948800181.321</td>
</tr>
<tr>
  <th>Skew:</th>           <td>25.506</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>   
</tr>
<tr>
  <th>Kurtosis:</th>       <td>957.399</td>  <th>  Cond. No.          </th>   <td>1.07e+07</td>   
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.07e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems.