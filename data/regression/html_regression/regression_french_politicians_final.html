<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>impression_count</td> <th>  R-squared:         </th> <td>   0.474</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.473</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   590.6</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 07 Jun 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  
</tr>
<tr>
  <th>Time:</th>                 <td>22:45:20</td>     <th>  Log-Likelihood:    </th> <td> -24490.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td> 14434</td>      <th>  AIC:               </th> <td>4.903e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 14411</td>      <th>  BIC:               </th> <td>4.920e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>    22</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
                <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                    <td>   -0.7934</td> <td>    0.164</td> <td>   -4.825</td> <td> 0.000</td> <td>   -1.116</td> <td>   -0.471</td>
</tr>
<tr>
  <th>dummy_annehidalgo</th>            <td>   -0.9734</td> <td>    0.100</td> <td>   -9.732</td> <td> 0.000</td> <td>   -1.169</td> <td>   -0.777</td>
</tr>
<tr>
  <th>dummy_emmanuelmacron</th>         <td>    0.1723</td> <td>    0.055</td> <td>    3.157</td> <td> 0.002</td> <td>    0.065</td> <td>    0.279</td>
</tr>
<tr>
  <th>dummy_florianphilippot</th>       <td>    0.7225</td> <td>    0.077</td> <td>    9.347</td> <td> 0.000</td> <td>    0.571</td> <td>    0.874</td>
</tr>
<tr>
  <th>dummy_francepoliticalfigures</th> <td>   -0.3449</td> <td>    0.070</td> <td>   -4.893</td> <td> 0.000</td> <td>   -0.483</td> <td>   -0.207</td>
</tr>
<tr>
  <th>dummy_francepolitics</th>         <td>    0.3934</td> <td>    0.055</td> <td>    7.188</td> <td> 0.000</td> <td>    0.286</td> <td>    0.501</td>
</tr>
<tr>
  <th>dummy_frenchqag</th>              <td>    0.0736</td> <td>    0.047</td> <td>    1.551</td> <td> 0.121</td> <td>   -0.019</td> <td>    0.167</td>
</tr>
<tr>
  <th>dummy_gralddarmanin</th>          <td>    0.9012</td> <td>    0.099</td> <td>    9.107</td> <td> 0.000</td> <td>    0.707</td> <td>    1.095</td>
</tr>
<tr>
  <th>dummy_jordanbardella</th>         <td>    0.6919</td> <td>    0.086</td> <td>    8.063</td> <td> 0.000</td> <td>    0.524</td> <td>    0.860</td>
</tr>
<tr>
  <th>dummy_lisabethborne</th>          <td>    1.2189</td> <td>    0.096</td> <td>   12.632</td> <td> 0.000</td> <td>    1.030</td> <td>    1.408</td>
</tr>
<tr>
  <th>dummy_marinelepen</th>            <td>   -0.7076</td> <td>    0.093</td> <td>   -7.606</td> <td> 0.000</td> <td>   -0.890</td> <td>   -0.525</td>
</tr>
<tr>
  <th>dummy_nicolasdupontaignan</th>    <td>   -0.4130</td> <td>    0.083</td> <td>   -4.971</td> <td> 0.000</td> <td>   -0.576</td> <td>   -0.250</td>
</tr>
<tr>
  <th>dummy_ricciotti</th>              <td>   -0.6792</td> <td>    0.083</td> <td>   -8.218</td> <td> 0.000</td> <td>   -0.841</td> <td>   -0.517</td>
</tr>
<tr>
  <th>dummy_riczemmour</th>             <td>    1.2975</td> <td>    0.094</td> <td>   13.869</td> <td> 0.000</td> <td>    1.114</td> <td>    1.481</td>
</tr>
<tr>
  <th>dummy_sandrinerousseau</th>       <td>    2.6472</td> <td>    0.102</td> <td>   25.890</td> <td> 0.000</td> <td>    2.447</td> <td>    2.848</td>
</tr>
<tr>
  <th>hashtags_count</th>               <td>   -0.1479</td> <td>    0.024</td> <td>   -6.114</td> <td> 0.000</td> <td>   -0.195</td> <td>   -0.100</td>
</tr>
<tr>
  <th>mentions_count</th>               <td>   -0.6557</td> <td>    0.023</td> <td>  -28.710</td> <td> 0.000</td> <td>   -0.700</td> <td>   -0.611</td>
</tr>
<tr>
  <th>tweet_external_urls_count</th>    <td>    0.1006</td> <td>    0.039</td> <td>    2.566</td> <td> 0.010</td> <td>    0.024</td> <td>    0.177</td>
</tr>
<tr>
  <th>tweet_length</th>                 <td>    0.3741</td> <td>    0.022</td> <td>   16.844</td> <td> 0.000</td> <td>    0.331</td> <td>    0.418</td>
</tr>
<tr>
  <th>tweet_medias_count</th>           <td>    0.0927</td> <td>    0.029</td> <td>    3.160</td> <td> 0.002</td> <td>    0.035</td> <td>    0.150</td>
</tr>
<tr>
  <th>tweet_period</th>                 <td>    0.0789</td> <td>    0.019</td> <td>    4.163</td> <td> 0.000</td> <td>    0.042</td> <td>    0.116</td>
</tr>
<tr>
  <th>tweet_sentiment</th>              <td>   -0.1124</td> <td>    0.032</td> <td>   -3.522</td> <td> 0.000</td> <td>   -0.175</td> <td>   -0.050</td>
</tr>
<tr>
  <th>followers_count</th>              <td>    0.6733</td> <td>    0.009</td> <td>   72.982</td> <td> 0.000</td> <td>    0.655</td> <td>    0.691</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>739.401</td> <th>  Durbin-Watson:     </th> <td>   1.353</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1283.675</td> 
</tr>
<tr>
  <th>Skew:</th>          <td> 0.412</td>  <th>  Prob(JB):          </th> <td>1.79e-279</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.207</td>  <th>  Cond. No.          </th> <td>    206.</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.