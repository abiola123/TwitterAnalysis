<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>impression_count</td> <th>  R-squared:         </th> <td>   0.474</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.473</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   464.5</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 07 Jun 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  
</tr>
<tr>
  <th>Time:</th>                 <td>22:45:20</td>     <th>  Log-Likelihood:    </th> <td> -24486.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td> 14434</td>      <th>  AIC:               </th> <td>4.903e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 14405</td>      <th>  BIC:               </th> <td>4.925e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
                <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                    <td>   -0.8073</td> <td>    0.172</td> <td>   -4.681</td> <td> 0.000</td> <td>   -1.145</td> <td>   -0.469</td>
</tr>
<tr>
  <th>dummy_annehidalgo</th>            <td>   -0.9515</td> <td>    0.104</td> <td>   -9.137</td> <td> 0.000</td> <td>   -1.156</td> <td>   -0.747</td>
</tr>
<tr>
  <th>dummy_emmanuelmacron</th>         <td>    0.1909</td> <td>    0.056</td> <td>    3.398</td> <td> 0.001</td> <td>    0.081</td> <td>    0.301</td>
</tr>
<tr>
  <th>dummy_florianphilippot</th>       <td>    0.6458</td> <td>    0.086</td> <td>    7.538</td> <td> 0.000</td> <td>    0.478</td> <td>    0.814</td>
</tr>
<tr>
  <th>dummy_francepoliticalfigures</th> <td>   -0.3329</td> <td>    0.073</td> <td>   -4.581</td> <td> 0.000</td> <td>   -0.475</td> <td>   -0.190</td>
</tr>
<tr>
  <th>dummy_francepolitics</th>         <td>    0.2675</td> <td>    0.074</td> <td>    3.615</td> <td> 0.000</td> <td>    0.122</td> <td>    0.413</td>
</tr>
<tr>
  <th>dummy_frenchqag</th>              <td>    0.1466</td> <td>    0.063</td> <td>    2.345</td> <td> 0.019</td> <td>    0.024</td> <td>    0.269</td>
</tr>
<tr>
  <th>dummy_gralddarmanin</th>          <td>    0.9065</td> <td>    0.099</td> <td>    9.153</td> <td> 0.000</td> <td>    0.712</td> <td>    1.101</td>
</tr>
<tr>
  <th>dummy_jeanlucmlenchon</th>        <td>    0.0403</td> <td>    0.086</td> <td>    0.470</td> <td> 0.638</td> <td>   -0.128</td> <td>    0.209</td>
</tr>
<tr>
  <th>dummy_jordanbardella</th>         <td>    0.6033</td> <td>    0.094</td> <td>    6.388</td> <td> 0.000</td> <td>    0.418</td> <td>    0.788</td>
</tr>
<tr>
  <th>dummy_lisabethborne</th>          <td>    1.2168</td> <td>    0.097</td> <td>   12.609</td> <td> 0.000</td> <td>    1.028</td> <td>    1.406</td>
</tr>
<tr>
  <th>dummy_marinelepen</th>            <td>   -0.6884</td> <td>    0.096</td> <td>   -7.208</td> <td> 0.000</td> <td>   -0.876</td> <td>   -0.501</td>
</tr>
<tr>
  <th>dummy_nathalieloiseau</th>        <td>   -0.0339</td> <td>    0.106</td> <td>   -0.321</td> <td> 0.748</td> <td>   -0.241</td> <td>    0.173</td>
</tr>
<tr>
  <th>dummy_news</th>                   <td>   -0.0223</td> <td>    0.059</td> <td>   -0.380</td> <td> 0.704</td> <td>   -0.138</td> <td>    0.093</td>
</tr>
<tr>
  <th>dummy_nicolasdupontaignan</th>    <td>   -0.4004</td> <td>    0.086</td> <td>   -4.649</td> <td> 0.000</td> <td>   -0.569</td> <td>   -0.232</td>
</tr>
<tr>
  <th>dummy_politicalfigures</th>       <td>    0.0737</td> <td>    0.085</td> <td>    0.868</td> <td> 0.385</td> <td>   -0.093</td> <td>    0.240</td>
</tr>
<tr>
  <th>dummy_politicalissues</th>        <td>   -0.0976</td> <td>    0.089</td> <td>   -1.098</td> <td> 0.272</td> <td>   -0.272</td> <td>    0.077</td>
</tr>
<tr>
  <th>dummy_politics</th>               <td>    0.1337</td> <td>    0.080</td> <td>    1.667</td> <td> 0.095</td> <td>   -0.023</td> <td>    0.291</td>
</tr>
<tr>
  <th>dummy_ricciotti</th>              <td>   -0.6634</td> <td>    0.086</td> <td>   -7.738</td> <td> 0.000</td> <td>   -0.831</td> <td>   -0.495</td>
</tr>
<tr>
  <th>dummy_riczemmour</th>             <td>    1.3098</td> <td>    0.096</td> <td>   13.644</td> <td> 0.000</td> <td>    1.122</td> <td>    1.498</td>
</tr>
<tr>
  <th>dummy_sandrinerousseau</th>       <td>    2.6400</td> <td>    0.103</td> <td>   25.743</td> <td> 0.000</td> <td>    2.439</td> <td>    2.841</td>
</tr>
<tr>
  <th>hashtags_count</th>               <td>   -0.1444</td> <td>    0.024</td> <td>   -5.915</td> <td> 0.000</td> <td>   -0.192</td> <td>   -0.097</td>
</tr>
<tr>
  <th>mentions_count</th>               <td>   -0.6556</td> <td>    0.023</td> <td>  -28.560</td> <td> 0.000</td> <td>   -0.701</td> <td>   -0.611</td>
</tr>
<tr>
  <th>tweet_external_urls_count</th>    <td>    0.0996</td> <td>    0.039</td> <td>    2.539</td> <td> 0.011</td> <td>    0.023</td> <td>    0.176</td>
</tr>
<tr>
  <th>tweet_length</th>                 <td>    0.3718</td> <td>    0.022</td> <td>   16.592</td> <td> 0.000</td> <td>    0.328</td> <td>    0.416</td>
</tr>
<tr>
  <th>tweet_medias_count</th>           <td>    0.0949</td> <td>    0.029</td> <td>    3.225</td> <td> 0.001</td> <td>    0.037</td> <td>    0.152</td>
</tr>
<tr>
  <th>tweet_period</th>                 <td>    0.0768</td> <td>    0.019</td> <td>    4.042</td> <td> 0.000</td> <td>    0.040</td> <td>    0.114</td>
</tr>
<tr>
  <th>tweet_sentiment</th>              <td>   -0.1128</td> <td>    0.032</td> <td>   -3.527</td> <td> 0.000</td> <td>   -0.175</td> <td>   -0.050</td>
</tr>
<tr>
  <th>followers_count</th>              <td>    0.6704</td> <td>    0.010</td> <td>   68.896</td> <td> 0.000</td> <td>    0.651</td> <td>    0.689</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>736.566</td> <th>  Durbin-Watson:     </th> <td>   1.353</td> 
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1272.116</td> 
</tr>
<tr>
  <th>Skew:</th>          <td> 0.412</td>  <th>  Prob(JB):          </th> <td>5.80e-277</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.199</td>  <th>  Cond. No.          </th> <td>    222.</td> 
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.