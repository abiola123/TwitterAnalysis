{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>impression_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914815520842616834</td>\n",
       "      <td>1629913861737283585</td>\n",
       "      <td>2023-02-26 18:38:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3446</td>\n",
       "      <td>97107</td>\n",
       "      <td>2211</td>\n",
       "      <td>6854</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>914815520842616834</td>\n",
       "      <td>1629913861737283585</td>\n",
       "      <td>2023-02-26 18:38:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3446</td>\n",
       "      <td>97107</td>\n",
       "      <td>2211</td>\n",
       "      <td>6854</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>914815520842616834</td>\n",
       "      <td>1629913861737283585</td>\n",
       "      <td>2023-02-26 18:38:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3446</td>\n",
       "      <td>97095</td>\n",
       "      <td>2211</td>\n",
       "      <td>6854</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>914815520842616834</td>\n",
       "      <td>1629913861737283585</td>\n",
       "      <td>2023-02-26 18:38:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3446</td>\n",
       "      <td>97095</td>\n",
       "      <td>2211</td>\n",
       "      <td>6854</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914815520842616834</td>\n",
       "      <td>1629304017087090689</td>\n",
       "      <td>2023-02-25 02:15:23+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>17557</td>\n",
       "      <td>97107</td>\n",
       "      <td>2211</td>\n",
       "      <td>6854</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author_id                   id                created_at  \\\n",
       "0  914815520842616834  1629913861737283585 2023-02-26 18:38:41+00:00   \n",
       "1  914815520842616834  1629913861737283585 2023-02-26 18:38:41+00:00   \n",
       "2  914815520842616834  1629913861737283585 2023-02-26 18:38:41+00:00   \n",
       "3  914815520842616834  1629913861737283585 2023-02-26 18:38:41+00:00   \n",
       "4  914815520842616834  1629304017087090689 2023-02-25 02:15:23+00:00   \n",
       "\n",
       "   retweet_count  reply_count  like_count  quote_count  impression_count  \\\n",
       "0              0            4          19            0              3446   \n",
       "1              0            4          19            0              3446   \n",
       "2              0            4          19            0              3446   \n",
       "3              0            4          19            0              3446   \n",
       "4              4           22         165            0             17557   \n",
       "\n",
       "   followers_count  following_count  tweet_count  listed_count  \n",
       "0            97107             2211         6854           504  \n",
       "1            97107             2211         6854           504  \n",
       "2            97095             2211         6854           504  \n",
       "3            97095             2211         6854           504  \n",
       "4            97107             2211         6854           504  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "american_politicians_df = pd.read_parquet('../data/american_politicians/parquet/', engine='pyarrow')\n",
    "# Parse the date column to datetime\n",
    "american_politicians_df['created_at'] = pd.to_datetime(american_politicians_df['created_at'])\n",
    "display(american_politicians_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatterplots(df, columns, x_label):\n",
    "    \"\"\"Plot scatterplots of the given columns against the x_label.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to plot.\n",
    "    columns : list\n",
    "        The columns to plot.\n",
    "    x_label : str\n",
    "        The column to plot on the x-axis.\n",
    "        \"\"\"\n",
    "    nb_rows = len(columns)\n",
    "    height = 4 * nb_rows\n",
    "    fig, axes = plt.subplots(nb_rows, 2, figsize=(16, height))\n",
    "    colors = ['royalblue', 'dodgerblue', 'cornflowerblue', 'skyblue', 'lightsteelblue', 'lightblue', 'lightskyblue', 'powderblue']\n",
    "    i = 0 \n",
    "\n",
    "    for column in columns:\n",
    "        x_label_fmt = x_label.replace('_', ' ').title()\n",
    "        y_label_fmt = column.replace('_', ' ').title()\n",
    "\n",
    "        axes = axes.flatten()\n",
    "        ax1 = axes[i//2*2]\n",
    "        sns.scatterplot(x=df[x_label], y=df[column], color=colors[i//2], alpha=0.5, ax=ax1)\n",
    "        sns.regplot(x=df[x_label], y=df[column], color=colors[i//2], scatter=True, ax=ax1)\n",
    "        ax1.set_xlabel(x_label_fmt, fontsize=8)\n",
    "        ax1.set_ylabel(y_label_fmt, fontsize=8)\n",
    "        ax1.set_title(f'{y_label_fmt} as a Function of {x_label_fmt} in Linear Scale', fontsize=9)\n",
    "        ax1.set_xscale('linear')\n",
    "        ax1.set_yscale('linear')\n",
    "        \n",
    "        ax2 = axes[i//2*2+(i+1)%2]\n",
    "        sns.scatterplot(x=df[x_label], y=df[column], color=colors[i//2], alpha=0.5, ax=ax2)\n",
    "        ax2.set_xlabel(x_label_fmt, fontsize=8)\n",
    "        ax2.set_ylabel(y_label_fmt, fontsize=8)\n",
    "        ax2.set_title(f'{y_label_fmt} as a Function of {x_label_fmt} in Log Scale', fontsize=9)\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        \n",
    "        i += 2\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatterplots of the engagement counts against impression count\n",
    "columns = ['retweet_count', 'reply_count', 'like_count', 'quote_count']\n",
    "# plot_scatterplots(american_politicians_df, columns, 'impression_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatterplots of the impression counts against follower counts\n",
    "columns = ['impression_count']\n",
    "# plot_scatterplots(american_politicians_df, columns, 'followers_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET FEATURES FROM DATAFRAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet info:\n",
    "- Tweet length  âœ…\n",
    "- Time of the tweet (morning, afternoon, night) âœ…\n",
    "- Sentiment of the tweet (score computed by model) âœ…\n",
    "- Number of hashtags âœ…\n",
    "- Number of mentions âœ…\n",
    "- Number of url's âœ…\n",
    "- Media type (video, image, text,..) => attention c un tableau\n",
    "- (To clarify: location) ðŸš§\n",
    "\n",
    "User info:\n",
    "- Verified âœ…\n",
    "- Profile creation date âœ…\n",
    "- (To clarify: Tweet frequency) ðŸš§"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/03 23:37:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://tsf-428-wpa-5-188.epfl.ch:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc4b81c26a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Import spark and open json file\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"20g\").getOrCreate()\n",
    "df = spark.read.json('../data/american_politicians/tweets.jsonl')\n",
    "json_rdd = df.rdd\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'GOOD NEWS: Iâ€™m pleased @USDOT is investing more than $1 MILLION in planning and developing a new corridor in southern West Virginia, which will expand and enhance transportation options for Bluefield area residents and visitors. MORE: https://t.co/EAciQ0Tjj8',\n",
       "  'context_annotations': [Row(domain=Row(description='Entity Service top level domain, every item that is in Entity Service should be in this domain', id='30', name='Entities [Entity Service]'), entity=Row(description=None, id='781974596752842752', name='Services')),\n",
       "   Row(domain=Row(description='Categories within Brand Verticals that narrow down the scope of Brands', id='46', name='Business Taxonomy'), entity=Row(description='Brands, companies, advertisers and every non-person handle with the profit intent related to Banks, Credit cards, Insurance, Investments, Stocks ', id='1557696848252391426', name='Financial Services Business')),\n",
       "   Row(domain=Row(description='Products created by Brands.  Examples: Ford Explorer, Apple iPhone.', id='48', name='Product'), entity=Row(description=None, id='1412579054855671809', name='Google Innovation')),\n",
       "   Row(domain=Row(description='States, provinces, or prefectures, like California or Fukushima Prefecture', id='159', name='States'), entity=Row(description='West Virginia', id='1016386746685128705', name='West Virginia')),\n",
       "   Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': None},\n",
       " {'text': 'WATCH: This week, I toured @wincorewindows in Parkersburg. As governor, I was proud to help this facility open its doors in 2007. Now, thanks to the #InflationReductionAct, consumers can save up to $3,200 annually on energy efficient home upgrades, including new windows &amp; doors. https://t.co/sjrBgCubZd',\n",
       "  'context_annotations': [Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Political issues', id='900740740468191232', name='Political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1291447199595782144', name='United States politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1518689897296453633', name='United States political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1559626214846869504', name='Inflation in the United States')),\n",
       "   Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=56, normalized_text='Parkersburg', probability=0.9789, start=46, type='Place')]},\n",
       " {'text': 'This week I urged @CMSGov to authorize an extension of the Low Wage Index Hospital Policy. This would allow hospitals in rural areas to compete for &amp; retain high-quality staff by increasing reimbursements to hospitals in rural areas w/ lower overall wages. https://t.co/LvJgUEJhp3',\n",
       "  'context_annotations': [Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=88, normalized_text='Low Wage Index Hospital Policy', probability=0.7076, start=59, type='Other')]},\n",
       " {'text': 'The East Palestine, OH train derailment raises serious questions around equipment maintenance, inspections, &amp; existing safety systems intended to prevent these accidents. Thatâ€™s why I wrote a letter to @SecretaryPete. People deserve answers. MORE: https://t.co/spjrQAc1cB',\n",
       "  'context_annotations': [Row(domain=Row(description='Real world events. ', id='29', name='Events [Entity Service]'), entity=Row(description=None, id='1626397107090325504', name='Ohio Chemical Disaster')),\n",
       "   Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=17, normalized_text='Palestine', probability=0.388, start=9, type='Place'),\n",
       "   Row(end=21, normalized_text='OH', probability=0.9202, start=20, type='Place')]},\n",
       " {'text': 'WATCH: Yesterday I visited the Wood County Senior Center to inform Parkersburg-area senior citizens about the many healthcare savings the #InflationReductionAct will bring for #WV seniors. Watch to learn more about how the #IRA is already helping seniors. @wtaptelevision https://t.co/CmGYO5kvrb',\n",
       "  'context_annotations': [Row(domain=Row(description='Top level interests and hobbies groupings, like Food or Travel', id='65', name='Interests and Hobbies Vertical'), entity=Row(description='Family and Life Stages', id='864925500627484672', name='Family and life stages')),\n",
       "   Row(domain=Row(description='A grouping of interests and hobbies entities, like Novelty Food or Destinations', id='66', name='Interests and Hobbies Category'), entity=Row(description='Caregiving', id='1092545020932976640', name='Caregiving')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Political issues', id='900740740468191232', name='Political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1291447199595782144', name='United States politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1518689897296453633', name='United States political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1559626214846869504', name='Inflation in the United States')),\n",
       "   Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Top level interests and hobbies groupings, like Food or Travel', id='65', name='Interests and Hobbies Vertical'), entity=Row(description='Family and Life Stages', id='864925500627484672', name='Family and life stages')),\n",
       "   Row(domain=Row(description='A grouping of interests and hobbies entities, like Novelty Food or Destinations', id='66', name='Interests and Hobbies Category'), entity=Row(description='Elder care', id='847547735393710080', name='Elder care')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=55, normalized_text='Wood County Senior Center', probability=0.6148, start=31, type='Place'),\n",
       "   Row(end=77, normalized_text='Parkersburg', probability=0.8453, start=67, type='Place'),\n",
       "   Row(end=178, normalized_text='WV', probability=0.4709, start=177, type='Other'),\n",
       "   Row(end=226, normalized_text='IRA', probability=0.6219, start=224, type='Organization')]},\n",
       " {'text': 'Form Energyâ€™s manufacturing plant to be built in Weirton is truly a team effort made possible by bipartisan cooperation. And let me be clear, without the #InflationReductionAct that I wrote, todayâ€™s announcement &amp; the 750 #jobs that come with it would not be possible. https://t.co/gTJ3lbUjSr',\n",
       "  'context_annotations': [Row(domain=Row(description='Television shows from around the world', id='3', name='TV Shows'), entity=Row(description=None, id='10050741930', name='The State')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Political issues', id='900740740468191232', name='Political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1291447199595782144', name='United States politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1518689897296453633', name='United States political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1559626214846869504', name='Inflation in the United States')),\n",
       "   Row(domain=Row(description='States, provinces, or prefectures, like California or Fukushima Prefecture', id='159', name='States'), entity=Row(description='West Virginia', id='1016386746685128705', name='West Virginia')),\n",
       "   Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=55, normalized_text='Weirton', probability=0.9923, start=49, type='Place')]},\n",
       " {'text': 'RT @AARPWV: In todayâ€™s @NewsandSentinel,  @Sen_JoeManchin visits Wood County Thursday to tout the benefits of the Inflation Reduction Act fâ€¦',\n",
       "  'context_annotations': [Row(domain=Row(description='Interests, opinions, and behaviors of individuals, groups, or cultures; like Speciality Cooking or Theme Parks', id='67', name='Interests and Hobbies'), entity=Row(description=None, id='1486458201117642754', name='Inflation')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Political issues', id='900740740468191232', name='Political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1291447199595782144', name='United States politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1518689897296453633', name='United States political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1559626214846869504', name='Inflation in the United States')),\n",
       "   Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=75, normalized_text='Wood County', probability=0.9468, start=65, type='Place')]},\n",
       " {'text': 'RT @EnergyDems: Chairman @Sen_JoeManchin and Sen. @lisamurkowski introduced the North American Transatlantic Resource Security Partnershipâ€¦',\n",
       "  'context_annotations': [Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Lisa Murkowski (AK)', id='888173937934213120', name='Lisa Murkowski')),\n",
       "   Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Lisa Murkowski (AK)', id='888173937934213120', name='Lisa Murkowski')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Lisa Murkowski (AK)', id='888173937934213120', name='Lisa Murkowski')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=137, normalized_text='North American Transatlantic Resource Security Partnership', probability=0.6226, start=80, type='Other')]},\n",
       " {'text': 'Just finished touring @wincorewindows manufacturing facility in Parkersburg. As Governor, I was proud to help Wincore open its doors in 2007, and thanks to the #InflationReductionAct, consumers can save up to $3,200 annually on energy efficient door, window &amp; insulation upgrades. https://t.co/HZbCTgPdAS',\n",
       "  'context_annotations': [Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Political issues', id='900740740468191232', name='Political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1291447199595782144', name='United States politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1518689897296453633', name='United States political issues')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description=None, id='1559626214846869504', name='Inflation in the United States')),\n",
       "   Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=74, normalized_text='Parkersburg', probability=0.9654, start=64, type='Place'),\n",
       "   Row(end=116, normalized_text='Wincore', probability=0.3799, start=110, type='Other')]},\n",
       " {'text': 'RT @AARPWV: Thanks @Sen_JoeManchin for the opportunity to join you today at the new Wood Co. Senior Center in downtown Parkersburg to discuâ€¦',\n",
       "  'context_annotations': [Row(domain=Row(description='Named people in the world like Nelson Mandela', id='10', name='Person'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='Politicians in the world, like Joe Biden', id='35', name='Politician'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politics', id='847878884917886977', name='Politics')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='US Senator Joe Manchin (WV)', id='888190307216506881', name='Joe Manchin')),\n",
       "   Row(domain=Row(description='A taxonomy of user interests. ', id='131', name='Unified Twitter Taxonomy'), entity=Row(description='Politician', id='1070032753834438656', name='Political figures'))],\n",
       "  'inner_annotations': [Row(end=90, normalized_text='Wood Co', probability=0.5591, start=84, type='Place'),\n",
       "   Row(end=129, normalized_text='Parkersburg', probability=0.9305, start=119, type='Place')]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_rdd.flatMap(lambda x: x['data']).map(lambda x: {'text':x['text'],'context_annotations':x['context_annotations'], 'inner_annotations':x['entities']['annotations']}).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1551"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get total number of tweets\n",
    "json_rdd.flatMap(lambda x: x['data']).count()\n",
    "\n",
    "#get total number of tweets without context annotations\n",
    "json_rdd.flatMap(lambda x: x['data']).filter(lambda x: not x['context_annotations']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find the most common context annotations that will be used for clustering later \n",
    "\n",
    "annotations = json_rdd.flatMap(lambda x: x['data']).map(lambda x: x['context_annotations']).filter(lambda x: x is not None).flatMap(lambda x: list(set([y['entity']['name'] for y in x]))).map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y).sortBy(lambda x: x[1], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_annotations = annotations.filter(lambda x: x[1] > 750).collect()\n",
    "# remove the first one which is 'Politics' (present in nearly all tweets)\n",
    "most_frequent_annotations = list(\n",
    "    map(lambda x: x[0], most_frequent_annotations))[1:]\n",
    "\n",
    "annotation_dict = {annotation: index for index,\n",
    "                   annotation in enumerate(most_frequent_annotations)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Political figures': 0,\n",
       " 'Political issues': 1,\n",
       " 'Joe Biden': 2,\n",
       " 'United States politics': 3,\n",
       " 'Government institutions': 4,\n",
       " 'United States political issues': 5,\n",
       " 'Jeff Merkley': 6,\n",
       " 'United States Congress': 7,\n",
       " 'Ted Cruz': 8,\n",
       " 'North Carolina': 9,\n",
       " 'Roy Cooper': 10,\n",
       " 'John Cornyn': 11,\n",
       " 'Financial Services Business': 12,\n",
       " 'Wisconsin': 13,\n",
       " 'News': 14,\n",
       " 'Sports & Fitness Business': 15,\n",
       " 'Richard Blumenthal': 16,\n",
       " 'Global Economy': 17,\n",
       " 'Debbie Stabenow': 18,\n",
       " 'Ben Cardin': 19,\n",
       " 'Political News': 20,\n",
       " 'Business & finance': 21,\n",
       " 'United States Senate': 22,\n",
       " 'Lisa Murkowski': 23,\n",
       " 'Chris Coons': 24,\n",
       " 'Mark Warner': 25,\n",
       " 'Sports': 26,\n",
       " 'Chuck Schumer': 27,\n",
       " 'Sheldon Whitehouse': 28,\n",
       " 'Amy Klobuchar': 29,\n",
       " 'Joe Manchin': 30,\n",
       " 'Inflation in the United States': 31,\n",
       " 'Chris Murphy': 32,\n",
       " 'Seattle': 33}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3ecead42804ceda30ebefdf3199173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c955ed987804b3e9a4c0d1a0a3c7f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea973e95e4c444280d874c8fa0ce59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/58.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ee7f4430014ae2a53473f674c58ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a854ccbb477c410f8bfd7bffd6e2bc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114c6c66eeeb47289854e0c79cd1d2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "zero_shot_classifier1 = pipeline('zero-shot-classification',\n",
    "                                model='facebook/bart-large-mnli')\n",
    "\n",
    "zero_shot_classifier2 = pipeline('zero-shot-classification', model='roberta-large-mnli')\n",
    "\n",
    "zero_shot_classifier3 = pipeline(\n",
    "    'zero-shot-classification', model='huggingface/distilbert-base-uncased-finetuned-mnli')\n",
    "\n",
    "zero_shot_classifier4 = pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-3')\n",
    "\n",
    "zero_shot_classifier5 = pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-9')\n",
    "\n",
    "\n",
    "#broadcast_classifier = spark.sparkContext.broadcast(zero_shot_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Joe Biden is the 46th President of the United States, having taken office on January 20, 2021. He served as Vice President under President Barack Obama from 2009 to 2017. His presidency has focused on a range of issues, including COVID-19 pandemic response, climate change, immigration reform, and economic recovery.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.5 s, sys: 361 ms, total: 50.9 s\n",
      "Wall time: 8.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Joe Biden is the 46th President of the United States, having taken office on January 20, 2021. He served as Vice President under President Barack Obama from 2009 to 2017. His presidency has focused on a range of issues, including COVID-19 pandemic response, climate change, immigration reform, and economic recovery.',\n",
       " 'labels': ['Joe Biden',\n",
       "  'United States politics',\n",
       "  'Political figures',\n",
       "  'United States political issues',\n",
       "  'Government institutions',\n",
       "  'Political issues',\n",
       "  'Political News',\n",
       "  'News',\n",
       "  'Global Economy',\n",
       "  'Business & finance',\n",
       "  'Sports',\n",
       "  'Financial Services Business',\n",
       "  'Seattle',\n",
       "  'Sports & Fitness Business',\n",
       "  'Wisconsin',\n",
       "  'North Carolina',\n",
       "  'Inflation in the United States',\n",
       "  'United States Senate',\n",
       "  'United States Congress',\n",
       "  'Ben Cardin',\n",
       "  'Joe Manchin',\n",
       "  'Sheldon Whitehouse',\n",
       "  'Richard Blumenthal',\n",
       "  'Roy Cooper',\n",
       "  'Chris Murphy',\n",
       "  'Debbie Stabenow',\n",
       "  'Lisa Murkowski',\n",
       "  'Mark Warner',\n",
       "  'Jeff Merkley',\n",
       "  'Amy Klobuchar',\n",
       "  'Chris Coons',\n",
       "  'Chuck Schumer',\n",
       "  'John Cornyn',\n",
       "  'Ted Cruz'],\n",
       " 'scores': [0.32445213198661804,\n",
       "  0.3052716851234436,\n",
       "  0.17729952931404114,\n",
       "  0.0692843347787857,\n",
       "  0.03482997789978981,\n",
       "  0.028603602200746536,\n",
       "  0.015574869699776173,\n",
       "  0.00940018892288208,\n",
       "  0.0064720953814685345,\n",
       "  0.0036936067044734955,\n",
       "  0.0031595472246408463,\n",
       "  0.003047309583052993,\n",
       "  0.002666766755282879,\n",
       "  0.002433548215776682,\n",
       "  0.001651786849834025,\n",
       "  0.001440925640054047,\n",
       "  0.0010778212454169989,\n",
       "  0.0010423132916912436,\n",
       "  0.0006962728220969439,\n",
       "  0.0006404275773093104,\n",
       "  0.0006350105977617204,\n",
       "  0.0006120447651483119,\n",
       "  0.0005975749809294939,\n",
       "  0.0005964837037026882,\n",
       "  0.0005567817133851349,\n",
       "  0.0005521029816009104,\n",
       "  0.0005505889421328902,\n",
       "  0.0005352276493795216,\n",
       "  0.0005338825867511332,\n",
       "  0.0005111878272145987,\n",
       "  0.0005013179616071284,\n",
       "  0.0004082320083398372,\n",
       "  0.0003436786064412445,\n",
       "  0.0003271987952757627]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "zero_shot_classifier1(sentence, most_frequent_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.7 s, sys: 195 ms, total: 39.9 s\n",
      "Wall time: 6.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Joe Biden is the 46th President of the United States, having taken office on January 20, 2021. He served as Vice President under President Barack Obama from 2009 to 2017. His presidency has focused on a range of issues, including COVID-19 pandemic response, climate change, immigration reform, and economic recovery.',\n",
       " 'labels': ['Joe Biden',\n",
       "  'United States politics',\n",
       "  'United States political issues',\n",
       "  'Political figures',\n",
       "  'Political issues',\n",
       "  'Political News',\n",
       "  'News',\n",
       "  'Government institutions',\n",
       "  'Financial Services Business',\n",
       "  'Global Economy',\n",
       "  'Wisconsin',\n",
       "  'United States Congress',\n",
       "  'North Carolina',\n",
       "  'Sports & Fitness Business',\n",
       "  'Business & finance',\n",
       "  'United States Senate',\n",
       "  'Seattle',\n",
       "  'Debbie Stabenow',\n",
       "  'Sports',\n",
       "  'Lisa Murkowski',\n",
       "  'Sheldon Whitehouse',\n",
       "  'Jeff Merkley',\n",
       "  'Roy Cooper',\n",
       "  'Amy Klobuchar',\n",
       "  'Chris Coons',\n",
       "  'Mark Warner',\n",
       "  'John Cornyn',\n",
       "  'Inflation in the United States',\n",
       "  'Ben Cardin',\n",
       "  'Richard Blumenthal',\n",
       "  'Joe Manchin',\n",
       "  'Chris Murphy',\n",
       "  'Chuck Schumer',\n",
       "  'Ted Cruz'],\n",
       " 'scores': [0.3969351351261139,\n",
       "  0.21438412368297577,\n",
       "  0.11969001591205597,\n",
       "  0.08646082133054733,\n",
       "  0.031960226595401764,\n",
       "  0.02065342105925083,\n",
       "  0.014473052695393562,\n",
       "  0.011570439673960209,\n",
       "  0.00870308093726635,\n",
       "  0.008434031158685684,\n",
       "  0.0060445829294621944,\n",
       "  0.006013684906065464,\n",
       "  0.005979647394269705,\n",
       "  0.005799314472824335,\n",
       "  0.005444495007395744,\n",
       "  0.004976418800652027,\n",
       "  0.00461387587711215,\n",
       "  0.0037171985022723675,\n",
       "  0.0035620960406959057,\n",
       "  0.00355747202411294,\n",
       "  0.0032981750555336475,\n",
       "  0.0031158749479800463,\n",
       "  0.0030651201959699392,\n",
       "  0.003062819130718708,\n",
       "  0.0028876212891191244,\n",
       "  0.0028458863962441683,\n",
       "  0.0027102280873805285,\n",
       "  0.0025747078470885754,\n",
       "  0.0025153225287795067,\n",
       "  0.002512630308046937,\n",
       "  0.002313778968527913,\n",
       "  0.0021069617941975594,\n",
       "  0.0020541793201118708,\n",
       "  0.0019636093638837337]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "zero_shot_classifier2(sentence, most_frequent_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/zero_shot_classification.py:205\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to understand extra arguments \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(sequences, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:1101\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1100\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[1;32m   1102\u001b[0m         \u001b[39miter\u001b[39;49m(\n\u001b[1;32m   1103\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_iterator(\n\u001b[1;32m   1104\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1105\u001b[0m             )\n\u001b[1;32m   1106\u001b[0m         )\n\u001b[1;32m   1107\u001b[0m     )\n\u001b[1;32m   1108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(item, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[39m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/pipelines/zero_shot_classification.py:252\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.postprocess\u001b[0;34m(self, model_outputs, multi_label)\u001b[0m\n\u001b[1;32m    249\u001b[0m     scores \u001b[39m=\u001b[39m scores[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[39m# softmax the \"entailment\" logits over all candidate labels\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     entail_logits \u001b[39m=\u001b[39m reshaped_outputs[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mentailment_id]\n\u001b[1;32m    253\u001b[0m     scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(entail_logits) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mexp(entail_logits)\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    255\u001b[0m top_inds \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mreversed\u001b[39m(scores[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margsort()))\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "zero_shot_classifier3(sentence, most_frequent_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 s, sys: 184 ms, total: 27.5 s\n",
      "Wall time: 4.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Joe Biden is the 46th President of the United States, having taken office on January 20, 2021. He served as Vice President under President Barack Obama from 2009 to 2017. His presidency has focused on a range of issues, including COVID-19 pandemic response, climate change, immigration reform, and economic recovery.',\n",
       " 'labels': ['United States politics',\n",
       "  'Joe Biden',\n",
       "  'United States political issues',\n",
       "  'Political figures',\n",
       "  'Political issues',\n",
       "  'Government institutions',\n",
       "  'Political News',\n",
       "  'Global Economy',\n",
       "  'News',\n",
       "  'United States Senate',\n",
       "  'Inflation in the United States',\n",
       "  'North Carolina',\n",
       "  'Joe Manchin',\n",
       "  'Business & finance',\n",
       "  'Seattle',\n",
       "  'Financial Services Business',\n",
       "  'United States Congress',\n",
       "  'Roy Cooper',\n",
       "  'John Cornyn',\n",
       "  'Sports',\n",
       "  'Wisconsin',\n",
       "  'Chris Coons',\n",
       "  'Chuck Schumer',\n",
       "  'Ben Cardin',\n",
       "  'Lisa Murkowski',\n",
       "  'Chris Murphy',\n",
       "  'Sports & Fitness Business',\n",
       "  'Amy Klobuchar',\n",
       "  'Debbie Stabenow',\n",
       "  'Richard Blumenthal',\n",
       "  'Mark Warner',\n",
       "  'Ted Cruz',\n",
       "  'Sheldon Whitehouse',\n",
       "  'Jeff Merkley'],\n",
       " 'scores': [0.3091528117656708,\n",
       "  0.2193729132413864,\n",
       "  0.13791249692440033,\n",
       "  0.1240718811750412,\n",
       "  0.054907020181417465,\n",
       "  0.03564048931002617,\n",
       "  0.01568925566971302,\n",
       "  0.010548645630478859,\n",
       "  0.008110485039651394,\n",
       "  0.006934907287359238,\n",
       "  0.006329915951937437,\n",
       "  0.004282225854694843,\n",
       "  0.004229013342410326,\n",
       "  0.004166499711573124,\n",
       "  0.003937321715056896,\n",
       "  0.0037893455009907484,\n",
       "  0.0037219671066850424,\n",
       "  0.0036336660850793123,\n",
       "  0.003344965633004904,\n",
       "  0.003317689523100853,\n",
       "  0.0032725606579333544,\n",
       "  0.0032433615997433662,\n",
       "  0.0032108700834214687,\n",
       "  0.0030304109677672386,\n",
       "  0.002859364729374647,\n",
       "  0.0027576726861298084,\n",
       "  0.002737216418609023,\n",
       "  0.002597128739580512,\n",
       "  0.002577455248683691,\n",
       "  0.0024442230351269245,\n",
       "  0.0022613501641899347,\n",
       "  0.002178260125219822,\n",
       "  0.0018842688295990229,\n",
       "  0.0018523582257330418]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "zero_shot_classifier4(sentence, most_frequent_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.8 s, sys: 312 ms, total: 41.2 s\n",
      "Wall time: 6.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Joe Biden is the 46th President of the United States, having taken office on January 20, 2021. He served as Vice President under President Barack Obama from 2009 to 2017. His presidency has focused on a range of issues, including COVID-19 pandemic response, climate change, immigration reform, and economic recovery.',\n",
       " 'labels': ['Joe Biden',\n",
       "  'United States politics',\n",
       "  'Political figures',\n",
       "  'United States political issues',\n",
       "  'Political issues',\n",
       "  'Government institutions',\n",
       "  'Political News',\n",
       "  'News',\n",
       "  'Global Economy',\n",
       "  'Sports',\n",
       "  'Seattle',\n",
       "  'Business & finance',\n",
       "  'Sports & Fitness Business',\n",
       "  'United States Senate',\n",
       "  'Financial Services Business',\n",
       "  'United States Congress',\n",
       "  'Wisconsin',\n",
       "  'North Carolina',\n",
       "  'Sheldon Whitehouse',\n",
       "  'Joe Manchin',\n",
       "  'Ben Cardin',\n",
       "  'Chris Coons',\n",
       "  'Mark Warner',\n",
       "  'Chris Murphy',\n",
       "  'Inflation in the United States',\n",
       "  'Richard Blumenthal',\n",
       "  'Jeff Merkley',\n",
       "  'Lisa Murkowski',\n",
       "  'Chuck Schumer',\n",
       "  'John Cornyn',\n",
       "  'Debbie Stabenow',\n",
       "  'Roy Cooper',\n",
       "  'Amy Klobuchar',\n",
       "  'Ted Cruz'],\n",
       " 'scores': [0.30737727880477905,\n",
       "  0.23798395693302155,\n",
       "  0.22009515762329102,\n",
       "  0.10277557373046875,\n",
       "  0.03234298527240753,\n",
       "  0.026032358407974243,\n",
       "  0.01818457432091236,\n",
       "  0.010243220254778862,\n",
       "  0.004257503896951675,\n",
       "  0.003413780126720667,\n",
       "  0.00292827351950109,\n",
       "  0.002822589362040162,\n",
       "  0.0025712132919579744,\n",
       "  0.0024614662397652864,\n",
       "  0.002379836980253458,\n",
       "  0.002022593980655074,\n",
       "  0.0018324588891118765,\n",
       "  0.0016615435015410185,\n",
       "  0.001528558088466525,\n",
       "  0.0014443077379837632,\n",
       "  0.0013165586860850453,\n",
       "  0.0013118331553414464,\n",
       "  0.0012887484626844525,\n",
       "  0.001240131095983088,\n",
       "  0.0012232756707817316,\n",
       "  0.0012027632910758257,\n",
       "  0.001125046517699957,\n",
       "  0.0011048940941691399,\n",
       "  0.0010650493204593658,\n",
       "  0.0010180551325902343,\n",
       "  0.0009918252471834421,\n",
       "  0.0009682320524007082,\n",
       "  0.0009658200433477759,\n",
       "  0.0008185631595551968]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "zero_shot_classifier5(sentence, most_frequent_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Function to get the sentiment of a tweet\n",
    "def analyse_sentiment(x):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(x)\n",
    "    return vs['compound']\n",
    "\n",
    "# \n",
    "def add_key_value(x, key, value):\n",
    "    x[key] = value\n",
    "    return x\n",
    "\n",
    "\n",
    "def keep_medias_only(x):\n",
    "    urls = x['tweet_urls']\n",
    "    if not urls:\n",
    "        return []\n",
    "    media_urls = [url['media_key'] for url in urls if 'media_key' in url and url['media_key']]\n",
    "    return media_urls\n",
    "\n",
    "def get_number_medias(x):\n",
    "    return len(x['tweet_media_keys'])\n",
    "\n",
    "def get_number_external_urls(x):\n",
    "    return (len(x['tweet_urls']) if x['tweet_urls'] else 0) - x['tweet_medias_count']\n",
    "\n",
    "def get_period_of_day(x):\n",
    "    hour = datetime.strptime(x['tweet_date'],\"%Y-%m-%dT%H:%M:%S.%fZ\").hour\n",
    "    if hour >= 6 and hour < 12:\n",
    "        return 'morning'\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "\n",
    "def get_zero_shot_context_annotation(x, corpus):\n",
    "    classification = zero_shot_classifier(\n",
    "        x, corpus)\n",
    "\n",
    "    labels = classification['labels']\n",
    "    scores = classification['scores']\n",
    "    joined = list(zip(labels, scores))\n",
    "\n",
    "    threshold = 0.1\n",
    "    filtered = list(filter(lambda x: x[1] > threshold, joined))\n",
    "\n",
    "    return [x[0]for x in filtered]\n",
    "\n",
    "\n",
    "def one_hot_encoding(x, encoding_dict):\n",
    "    encoding = [0] * len(encoding_dict)\n",
    "\n",
    "    annotations = x['context_annotations']\n",
    "\n",
    "    if not annotations:\n",
    "        #zero shot classification here\n",
    "        print(\"AGAIN\")\n",
    "        text = x['tweet_text']\n",
    "        annotations = get_zero_shot_context_annotation(text, most_frequent_annotations)\n",
    "\n",
    "    for annotation in annotations:\n",
    "        # print(annotation)\n",
    "        if isinstance(annotation,str):\n",
    "            name = annotation\n",
    "        \n",
    "        elif not annotation['entity']:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            name = annotation['entity']['name']\n",
    "\n",
    "        if name in encoding_dict:\n",
    "           encoding[encoding_dict[name]] = 1\n",
    "\n",
    "    return encoding\n",
    "\n",
    "\n",
    "def add_dummy_encoding(x, column_names):\n",
    "    encoding = dict(zip(column_names, x['encoded_annotations']))\n",
    "\n",
    "    for key, value in encoding.items():\n",
    "\n",
    "        cleaned = re.sub('[^A-Za-z0-9_]+', '', key.lower())\n",
    "        cleaned = re.sub('__', '_', cleaned)\n",
    "\n",
    "        x[f'dummy_{\"_\".join(cleaned.split(\" \"))}'] = value\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def add_dummy_tweet_period(x):\n",
    "    time_of_day = x['tweet_period']\n",
    "\n",
    "    x['dummy_tweet_period_morning'] = 0\n",
    "    x['dummy_tweet_period_afternoon'] = 0\n",
    "    x['dummy_tweet_period_night'] = 0\n",
    "\n",
    "    x[f'dummy_tweet_period_{time_of_day}'] = 1\n",
    "\n",
    "    return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AGAINe 16:==> (1 + 1) / 2][Stage 29:==> (1 + 1) / 2][Stage 59:==> (2 + 1) / 3]\n"
     ]
    }
   ],
   "source": [
    "json_rdd_data_fields =json_rdd.filter(lambda x: x['data']).flatMap(lambda x: x['data']).filter(lambda x: x['entities']) \\\n",
    ".map(lambda x : {\n",
    "    'tweet_text': x['text'],\n",
    "    'tweet_date': x['created_at'],\n",
    "    'tweet_hashtags': x['entities']['hashtags'],\n",
    "    'tweet_mentions': x['entities']['mentions'],\n",
    "    'tweet_urls': x['entities']['urls'], \n",
    "    'user_id': x['author_id'],\n",
    "    'tweet_id': x['id'],\n",
    "    'context_annotations': x['context_annotations'] if x['context_annotations'] else [],\n",
    "    'impression_count': x['public_metrics']['impression_count'],\n",
    "    # 'retweet_count': x['public_metrics']['retweet_count'],\n",
    "    # 'reply_count': x['public_metrics']['reply_count'],\n",
    "    # 'like_count': x['public_metrics']['like_count'],\n",
    "})\n",
    "\n",
    "# adding sentiment analysis on the tweet text using vader to the data\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'tweet_sentiment', analyse_sentiment(x['tweet_text'])))\n",
    "\n",
    "# adding the tweet length to the data\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'tweet_length', len(x['tweet_text'])))\n",
    "\n",
    "# adding the number of hashtags to the data\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'hashtags_count', len(x['tweet_hashtags'])if x['tweet_hashtags'] else 0))\n",
    "\n",
    "# adding the number of mentions to the data\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'mentions_count', len(x['tweet_mentions'])if x['tweet_mentions'] else 0))\n",
    "\n",
    "# adding the media url's only to the data\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'tweet_media_keys', keep_medias_only(x)))\n",
    "\n",
    "# adding the number of medias to the data\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'tweet_medias_count', get_number_medias(x)))\n",
    "\n",
    "# adding the number of external urls to the data\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'tweet_external_urls_count', get_number_external_urls(x)))\n",
    "\n",
    "# adding the period of the day to the data\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'tweet_period', get_period_of_day(x)))\n",
    "\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : {k: v for k, v in x.items() if k not in ['tweet_mentions', 'tweet_urls', 'tweet_hashtags', 'tweets_media_count']})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# getting the annotations and putting them in clusters using one hot endcoding\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_key_value(x, 'encoded_annotations', one_hot_encoding(x, annotation_dict)))\n",
    "\n",
    "\n",
    "# GENERATE DUMMY VARIABLES FOR CATEGORICAL VARIABLES\n",
    "\n",
    "# add dummy variables after one hot encoding\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_dummy_encoding(x, most_frequent_annotations))\n",
    "\n",
    "json_rdd_data_fields = json_rdd_data_fields.map(lambda x : add_dummy_tweet_period(x))\n",
    "\n",
    "# 2. Create a dataframe from the rdd\n",
    "\n",
    "# transforming the data to a dataframe\n",
    "regression_df = json_rdd_data_fields.toDF().drop('context_annotations','encoded_annotations','tweet_date','tweet_media_keys','tweet_period').persist()\n",
    "\n",
    "\n",
    "# getting the followers count data\n",
    "json_rdd_followers = json_rdd.filter(lambda x: x['includes'] and x['data'] and x['includes']['users']).map(lambda x: {\n",
    "    'followers_count': x['includes']['users'][0]['public_metrics']['followers_count'], \n",
    "    'user_id': x['includes']['users'][0]['id']})\n",
    "\n",
    "# converting the rdd to a dataframe\n",
    "json_followers_df = json_rdd_followers.toDF()\n",
    "json_followers_df = json_followers_df.dropDuplicates(['user_id'])\n",
    "\n",
    "# 4. Join the two dataframes in order to get the media type for each tweet.\n",
    "# If a tweet has multiple media, we will get multiple rows for the same tweet id in the exploded dataframe\n",
    "# Then when performing the join, we will have a set of media types for each tweet id in the json_medias_per_tweet_df dataframe\n",
    "\n",
    "# regression_df = regression_df.join(\n",
    "# json_followers_df, on='user_id',how='inner').drop('user_id','tweet_id').persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AGAIN\n",
      "AGAIN\n",
      "AGAIN\n",
      "AGAIN\n",
      "AGAINe 16:==> (1 + 1) / 2][Stage 29:==> (1 + 1) / 2][Stage 33:>   (0 + 1) / 1]\n",
      "AGAIN\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/adeye/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/adeye/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/home/adeye/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/adeye/Documents/EPFL/MA4/semester_project/notebooks/04_ml.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/adeye/Documents/EPFL/MA4/semester_project/notebooks/04_ml.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m regression_df\u001b[39m.\u001b[39;49mshow(\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:606\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a bool\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(truncate, \u001b[39mbool\u001b[39m) \u001b[39mand\u001b[39;00m truncate:\n\u001b[0;32m--> 606\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mshowString(n, \u001b[39m20\u001b[39;49m, vertical))\n\u001b[1;32m    607\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regression_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regression_df_pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/adeye/Documents/EPFL/MA4/semester_project/notebooks/04_ml.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/adeye/Documents/EPFL/MA4/semester_project/notebooks/04_ml.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m regression_df_pd\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mregression_df.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regression_df_pd' is not defined"
     ]
    }
   ],
   "source": [
    "regression_df_pd.to_csv('regression_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regressor_columns_string(columns):\n",
    "  regressor_columns = list(filter(lambda x: x != 'impression_count',columns))\n",
    "  regressor_columns_string = \"+\".join(regressor_columns)\n",
    "  return regressor_columns_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       impression_count   R-squared:                       0.122\n",
      "Model:                            OLS   Adj. R-squared:                  0.121\n",
      "Method:                 Least Squares   F-statistic:                     125.8\n",
      "Date:                Tue, 02 May 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:57:52   Log-Likelihood:            -5.7808e+05\n",
      "No. Observations:               39117   AIC:                         1.156e+06\n",
      "Df Residuals:                   39073   BIC:                         1.157e+06\n",
      "Df Model:                          43                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================================\n",
      "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Intercept                          1.367e+05   1.26e+04     10.845      0.000    1.12e+05    1.61e+05\n",
      "dummy_amyklobuchar                -5.994e+04   2.42e+04     -2.481      0.013   -1.07e+05   -1.26e+04\n",
      "dummy_bencardin                   -5.421e+04   2.22e+04     -2.440      0.015   -9.77e+04   -1.07e+04\n",
      "dummy_businessfinance              1.004e+05    3.9e+04      2.576      0.010     2.4e+04    1.77e+05\n",
      "dummy_chriscoons                  -4.915e+04   2.31e+04     -2.131      0.033   -9.44e+04   -3944.821\n",
      "dummy_chrismurphy                  6492.9943   2.39e+04      0.271      0.786   -4.04e+04    5.34e+04\n",
      "dummy_chuckschumer                -3.066e+04   2.29e+04     -1.337      0.181   -7.56e+04    1.43e+04\n",
      "dummy_debbiestabenow              -2.462e+04   2.23e+04     -1.106      0.269   -6.83e+04     1.9e+04\n",
      "dummy_financialservicesbusiness   -1.807e+04   3.21e+04     -0.563      0.573   -8.09e+04    4.48e+04\n",
      "dummy_globaleconomy               -4.857e+04   2.15e+04     -2.256      0.024   -9.08e+04   -6379.609\n",
      "dummy_governmentinstitutions       4.971e+04   1.98e+04      2.516      0.012     1.1e+04    8.84e+04\n",
      "dummy_inflationintheunitedstates  -1.017e+04   3.07e+04     -0.331      0.740   -7.04e+04       5e+04\n",
      "dummy_jeffmerkley                 -6.396e+04   1.66e+04     -3.846      0.000   -9.66e+04   -3.14e+04\n",
      "dummy_joebiden                     1.027e+04   1.17e+04      0.880      0.379   -1.26e+04    3.32e+04\n",
      "dummy_joemanchin                   4.239e+04   2.37e+04      1.792      0.073   -3980.118    8.88e+04\n",
      "dummy_johncornyn                  -7.089e+04   1.85e+04     -3.836      0.000   -1.07e+05   -3.47e+04\n",
      "dummy_lisamurkowski               -5.763e+04   2.27e+04     -2.542      0.011   -1.02e+05   -1.32e+04\n",
      "dummy_markwarner                  -7.361e+04   2.38e+04     -3.091      0.002    -1.2e+05   -2.69e+04\n",
      "dummy_news                        -3.605e+04   1.99e+04     -1.813      0.070    -7.5e+04    2933.815\n",
      "dummy_northcarolina               -1.649e+05   2.25e+05     -0.734      0.463   -6.05e+05    2.75e+05\n",
      "dummy_politicalfigures            -7114.6475   9143.184     -0.778      0.436    -2.5e+04    1.08e+04\n",
      "dummy_politicalissues              4.575e+04   1.56e+04      2.932      0.003    1.52e+04    7.63e+04\n",
      "dummy_politicalnews                9.237e+04   2.46e+04      3.749      0.000    4.41e+04    1.41e+05\n",
      "dummy_richardblumenthal           -7.101e+04   2.14e+04     -3.311      0.001   -1.13e+05    -2.9e+04\n",
      "dummy_roycooper                    1.212e+05   2.25e+05      0.539      0.590    -3.2e+05    5.62e+05\n",
      "dummy_seattle                     -2.648e+04   2.42e+04     -1.093      0.274    -7.4e+04     2.1e+04\n",
      "dummy_sheldonwhitehouse           -5.976e+04   2.42e+04     -2.468      0.014   -1.07e+05   -1.23e+04\n",
      "dummy_sports                       1.169e+05   4.83e+04      2.423      0.015    2.23e+04    2.12e+05\n",
      "dummy_sportsfitnessbusiness        3102.0068    4.3e+04      0.072      0.942   -8.11e+04    8.73e+04\n",
      "dummy_tedcruz                      -981.8763   1.78e+04     -0.055      0.956   -3.58e+04    3.38e+04\n",
      "dummy_tweet_period_afternoon      -1.441e+04   1.02e+04     -1.415      0.157   -3.44e+04    5558.134\n",
      "dummy_tweet_period_morning           1.5e+05   2.63e+04      5.705      0.000    9.84e+04    2.01e+05\n",
      "dummy_tweet_period_night           1146.8601   9984.581      0.115      0.909   -1.84e+04    2.07e+04\n",
      "dummy_unitedstatescongress        -1.238e+04   3.06e+04     -0.404      0.686   -7.24e+04    4.76e+04\n",
      "dummy_unitedstatespoliticalissues -1.882e+05    2.9e+04     -6.480      0.000   -2.45e+05   -1.31e+05\n",
      "dummy_unitedstatespolitics          1.11e+05   1.82e+04      6.090      0.000    7.52e+04    1.47e+05\n",
      "dummy_unitedstatessenate           3.626e+04   3.25e+04      1.116      0.264   -2.74e+04    9.99e+04\n",
      "dummy_wisconsin                   -4.208e+04      2e+04     -2.104      0.035   -8.13e+04   -2886.794\n",
      "hashtags_count                    -2.582e+04   6258.525     -4.125      0.000   -3.81e+04   -1.36e+04\n",
      "mentions_count                    -4.297e+04   3649.172    -11.775      0.000   -5.01e+04   -3.58e+04\n",
      "tweet_external_urls_count          3636.7219   7068.887      0.514      0.607   -1.02e+04    1.75e+04\n",
      "tweet_length                       -214.2018     48.199     -4.444      0.000    -308.674    -119.730\n",
      "tweet_medias_count                 9264.7165   4237.355      2.186      0.029     959.395    1.76e+04\n",
      "tweet_sentiment                   -3.846e+04   6384.977     -6.023      0.000    -5.1e+04   -2.59e+04\n",
      "followers_count                       0.0332      0.000     66.564      0.000       0.032       0.034\n",
      "==============================================================================\n",
      "Omnibus:                    93185.042   Durbin-Watson:                   1.874\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       1294753586.300\n",
      "Skew:                          24.330   Prob(JB):                         0.00\n",
      "Kurtosis:                     892.955   Cond. No.                     1.03e+18\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.7e-18. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# ols regression follower count on the other variables\n",
    "import statsmodels.formula.api as smf\n",
    "regressor_columns_string = create_regressor_columns_string(regression_df_pd.columns)\n",
    "mod = smf.ols(formula=f'impression_count ~ {regressor_columns_string}', data=regression_df_pd)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dummy_amyklobuchar', 'dummy_bencardin', 'dummy_businessfinance',\n",
      "       'dummy_chriscoons', 'dummy_chrismurphy', 'dummy_chuckschumer',\n",
      "       'dummy_debbiestabenow', 'dummy_financialservicesbusiness',\n",
      "       'dummy_globaleconomy', 'dummy_governmentinstitutions',\n",
      "       'dummy_inflationintheunitedstates', 'dummy_jeffmerkley',\n",
      "       'dummy_joebiden', 'dummy_joemanchin', 'dummy_johncornyn',\n",
      "       'dummy_lisamurkowski', 'dummy_markwarner', 'dummy_news',\n",
      "       'dummy_northcarolina', 'dummy_politicalfigures',\n",
      "       'dummy_politicalissues', 'dummy_politicalnews',\n",
      "       'dummy_richardblumenthal', 'dummy_roycooper', 'dummy_seattle',\n",
      "       'dummy_sheldonwhitehouse', 'dummy_sports',\n",
      "       'dummy_sportsfitnessbusiness', 'dummy_tedcruz',\n",
      "       'dummy_tweet_period_afternoon', 'dummy_tweet_period_morning',\n",
      "       'dummy_tweet_period_night', 'dummy_unitedstatescongress',\n",
      "       'dummy_unitedstatespoliticalissues', 'dummy_unitedstatespolitics',\n",
      "       'dummy_unitedstatessenate', 'dummy_wisconsin', 'hashtags_count',\n",
      "       'impression_count', 'mentions_count', 'tweet_external_urls_count',\n",
      "       'tweet_length', 'tweet_medias_count', 'tweet_sentiment',\n",
      "       'followers_count'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummy_amyklobuchar</th>\n",
       "      <th>dummy_bencardin</th>\n",
       "      <th>dummy_businessfinance</th>\n",
       "      <th>dummy_chriscoons</th>\n",
       "      <th>dummy_chrismurphy</th>\n",
       "      <th>dummy_chuckschumer</th>\n",
       "      <th>dummy_debbiestabenow</th>\n",
       "      <th>dummy_financialservicesbusiness</th>\n",
       "      <th>dummy_globaleconomy</th>\n",
       "      <th>dummy_governmentinstitutions</th>\n",
       "      <th>...</th>\n",
       "      <th>dummy_unitedstatessenate</th>\n",
       "      <th>dummy_wisconsin</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>impression_count</th>\n",
       "      <th>mentions_count</th>\n",
       "      <th>tweet_external_urls_count</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_medias_count</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "      <th>followers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.145260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>97095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.773265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>97095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.119399</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>97095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.861492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>97095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.412791</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>97095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.833608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>87592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39113</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.385032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>87592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39114</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.977904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>87592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.519955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>87592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39116</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.282475</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>87592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39117 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dummy_amyklobuchar  dummy_bencardin  dummy_businessfinance  \\\n",
       "0                       0                0                      0   \n",
       "1                       0                0                      0   \n",
       "2                       0                0                      0   \n",
       "3                       0                0                      0   \n",
       "4                       0                0                      0   \n",
       "...                   ...              ...                    ...   \n",
       "39112                   0                0                      0   \n",
       "39113                   0                0                      0   \n",
       "39114                   0                0                      0   \n",
       "39115                   0                0                      0   \n",
       "39116                   0                0                      0   \n",
       "\n",
       "       dummy_chriscoons  dummy_chrismurphy  dummy_chuckschumer  \\\n",
       "0                     0                  0                   0   \n",
       "1                     0                  0                   0   \n",
       "2                     0                  0                   0   \n",
       "3                     0                  0                   0   \n",
       "4                     0                  0                   0   \n",
       "...                 ...                ...                 ...   \n",
       "39112                 0                  0                   0   \n",
       "39113                 0                  0                   0   \n",
       "39114                 0                  0                   0   \n",
       "39115                 0                  0                   0   \n",
       "39116                 0                  0                   0   \n",
       "\n",
       "       dummy_debbiestabenow  dummy_financialservicesbusiness  \\\n",
       "0                         0                                0   \n",
       "1                         0                                0   \n",
       "2                         0                                0   \n",
       "3                         0                                0   \n",
       "4                         0                                0   \n",
       "...                     ...                              ...   \n",
       "39112                     0                                0   \n",
       "39113                     0                                0   \n",
       "39114                     0                                0   \n",
       "39115                     0                                0   \n",
       "39116                     0                                0   \n",
       "\n",
       "       dummy_globaleconomy  dummy_governmentinstitutions  ...  \\\n",
       "0                        0                             0  ...   \n",
       "1                        0                             0  ...   \n",
       "2                        0                             0  ...   \n",
       "3                        0                             0  ...   \n",
       "4                        0                             0  ...   \n",
       "...                    ...                           ...  ...   \n",
       "39112                    0                             0  ...   \n",
       "39113                    0                             0  ...   \n",
       "39114                    0                             0  ...   \n",
       "39115                    0                             0  ...   \n",
       "39116                    0                             0  ...   \n",
       "\n",
       "       dummy_unitedstatessenate  dummy_wisconsin  hashtags_count  \\\n",
       "0                             0                0               0   \n",
       "1                             0                0               1   \n",
       "2                             0                0               0   \n",
       "3                             0                0               0   \n",
       "4                             0                0               0   \n",
       "...                         ...              ...             ...   \n",
       "39112                         0                0               1   \n",
       "39113                         0                0               1   \n",
       "39114                         0                0               1   \n",
       "39115                         0                0               1   \n",
       "39116                         0                0               1   \n",
       "\n",
       "       impression_count  mentions_count  tweet_external_urls_count  \\\n",
       "0              8.145260               0                          0   \n",
       "1              9.773265               0                          0   \n",
       "2              8.119399               0                          1   \n",
       "3              8.861492               1                          0   \n",
       "4              9.412791               0                          0   \n",
       "...                 ...             ...                        ...   \n",
       "39112          8.833608               0                          1   \n",
       "39113          8.385032               0                          0   \n",
       "39114          8.977904               0                          0   \n",
       "39115          9.519955               1                          0   \n",
       "39116          9.282475               3                          0   \n",
       "\n",
       "       tweet_length  tweet_medias_count  tweet_sentiment  followers_count  \n",
       "0                23                   1           0.0000            97095  \n",
       "1               156                   1           0.0000            97095  \n",
       "2               120                   1           0.5411            97095  \n",
       "3                62                   2           0.0000            97095  \n",
       "4               257                   1           0.8176            97095  \n",
       "...             ...                 ...              ...              ...  \n",
       "39112           287                   0           0.7964            87592  \n",
       "39113           233                   0           0.8555            87592  \n",
       "39114           254                   0           0.8807            87592  \n",
       "39115           278                   1           0.7964            87592  \n",
       "39116           200                   1           0.6996            87592  \n",
       "\n",
       "[39117 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       impression_count   R-squared:                       0.395\n",
      "Model:                            OLS   Adj. R-squared:                  0.394\n",
      "Method:                 Least Squares   F-statistic:                     878.2\n",
      "Date:                Tue, 02 May 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:57:52   Log-Likelihood:            -1.0000e+05\n",
      "No. Observations:               39117   AIC:                         2.001e+05\n",
      "Df Residuals:                   39087   BIC:                         2.003e+05\n",
      "Df Model:                          29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================================\n",
      "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "Intercept                             5.8661      0.052    111.742      0.000       5.763       5.969\n",
      "dummy_amyklobuchar                    2.4664      0.118     20.847      0.000       2.235       2.698\n",
      "dummy_bencardin                      -0.4943      0.109     -4.547      0.000      -0.707      -0.281\n",
      "dummy_businessfinance                 0.3925      0.111      3.539      0.000       0.175       0.610\n",
      "dummy_chuckschumer                    0.6795      0.112      6.049      0.000       0.459       0.900\n",
      "dummy_debbiestabenow                  0.8032      0.109      7.382      0.000       0.590       1.016\n",
      "dummy_globaleconomy                   0.5008      0.105      4.760      0.000       0.295       0.707\n",
      "dummy_governmentinstitutions          0.4988      0.077      6.472      0.000       0.348       0.650\n",
      "dummy_jeffmerkley                    -0.1877      0.081     -2.318      0.020      -0.346      -0.029\n",
      "dummy_johncornyn                     -0.4504      0.090     -5.009      0.000      -0.627      -0.274\n",
      "dummy_lisamurkowski                  -0.7225      0.111     -6.513      0.000      -0.940      -0.505\n",
      "dummy_news                            0.6586      0.097      6.756      0.000       0.468       0.850\n",
      "dummy_politicalissues                 0.2158      0.073      2.971      0.003       0.073       0.358\n",
      "dummy_richardblumenthal              -0.3539      0.105     -3.374      0.001      -0.559      -0.148\n",
      "dummy_roycooper                      -0.8931      0.086    -10.412      0.000      -1.061      -0.725\n",
      "dummy_seattle                         1.2190      0.119     10.271      0.000       0.986       1.452\n",
      "dummy_sheldonwhitehouse               0.7841      0.119      6.611      0.000       0.552       1.017\n",
      "dummy_sports                          1.7417      0.112     15.588      0.000       1.523       1.961\n",
      "dummy_tweet_period_afternoon          0.0599      0.033      1.788      0.074      -0.006       0.125\n",
      "dummy_tweet_period_morning            0.5993      0.173      3.466      0.001       0.260       0.938\n",
      "dummy_unitedstatespoliticalissues    -1.1678      0.129     -9.058      0.000      -1.421      -0.915\n",
      "dummy_unitedstatespolitics            1.2735      0.089     14.376      0.000       1.100       1.447\n",
      "dummy_unitedstatessenate             -0.5898      0.129     -4.584      0.000      -0.842      -0.338\n",
      "dummy_wisconsin                      -0.6169      0.098     -6.313      0.000      -0.808      -0.425\n",
      "hashtags_count                       -0.0925      0.031     -3.031      0.002      -0.152      -0.033\n",
      "mentions_count                       -2.0599      0.018   -117.475      0.000      -2.094      -2.026\n",
      "tweet_length                          0.0134      0.000     57.785      0.000       0.013       0.014\n",
      "tweet_medias_count                    0.5704      0.020     28.618      0.000       0.531       0.609\n",
      "tweet_sentiment                       0.1421      0.031      4.580      0.000       0.081       0.203\n",
      "followers_count                    7.564e-08   2.41e-09     31.344      0.000    7.09e-08    8.04e-08\n",
      "==============================================================================\n",
      "Omnibus:                      145.610   Durbin-Watson:                   1.561\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              166.572\n",
      "Skew:                          -0.100   Prob(JB):                     6.75e-37\n",
      "Kurtosis:                       3.250   Cond. No.                     7.50e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.5e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 15:29:23 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1338128 ms exceeds timeout 120000 ms\n",
      "23/05/02 15:29:23 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/05/02 15:29:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/05/02 15:29:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/05/02 15:29:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/05/02 15:29:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/05/02 15:29:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/05/02 15:29:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/05/02 15:29:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/05/02 15:29:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/05/02 15:29:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/05/02 15:29:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@tsf-428-wpa-5-004.epfl.ch:32829\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n"
     ]
    }
   ],
   "source": [
    "# Remove the variables that are not significant\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "print(regression_df_pd.columns)\n",
    "\n",
    "regression_df_pd['impression_count'] = np.log(1+ regression_df_pd['impression_count'])\n",
    "\n",
    "display(regression_df_pd)\n",
    "\n",
    "regressor_columns = list(filter(lambda x: x not in [\n",
    "                         'tweet_external_urls_count', 'dummy_tweet_period_night', 'dummy_joemanchin', 'dummy_chrismurphy', 'dummy_financialservicesbusiness', 'dummy_inflationintheunitedstates', 'dummy_joebiden', 'dummy_politicalfigures', 'dummy_northcarolina', 'dummy_tedcruz', 'dummy_sportsfitnessbusiness', 'dummy_unitedstatescongress', 'dummy_markwarner', 'dummy_politicalnews', 'dummy_chriscoons'], regression_df_pd.columns))\n",
    "\n",
    "regressor_columns_string = create_regressor_columns_string(\n",
    "    regressor_columns)\n",
    "mod = smf.ols(\n",
    "    formula=f'impression_count ~ {regressor_columns_string}', data=regression_df_pd)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "618"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_rdd_includes_fields =json_rdd \\\n",
    ".map(lambda x : {\n",
    "    'user_profile_creation_date': x['includes']['users'][0]['created_at'],\n",
    "    'user_verified': x['includes']['users'][0]['verified'],\n",
    "    'user_creation_date': x['includes']['users'][0]['created_at'],\n",
    "    'user_id': x['includes']['users'][0]['id'],\n",
    "})\n",
    "\n",
    "json_inclued_fields_df = json_rdd_includes_fields.toDF(['user_profile_creation_date', 'user_verified', 'user_creation_date', 'user_id'])\n",
    "\n",
    "json_inclued_fields_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
